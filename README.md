# ğŸ­ HADOOP_SPARK - E-Commerce Data Pipeline

---

## ğŸ“Œ Contexte

**Projet** : Pipeline Big Data complet pour plateforme e-commerce **ShopNow+**  
**MatiÃ¨re** : Architecture Big Data (Hadoop, Spark, Kafka)  
**Type** : Projet en Ã©quipe (3 personnes)  
**Stack** : MERN + Kafka + HDFS + Spark  

Application e-commerce full-stack avec **pipeline de donnÃ©es en temps rÃ©el** pour analyser les comportements clients, gÃ©rer les stocks et calculer des KPIs mÃ©tier.

---

## ğŸ‘¥ Ã‰quipe & Contributions

| RÃ´le | Personne | SpÃ©cialitÃ© |
|------|----------|-----------|
| **Front & Back** | Amaury TISSOT | React/Express - API REST |
| **Kafka** | LÃ©a DRUFFIN | Streaming et intÃ©gration Ã©vÃ©nementielle |
| **HDFS & Spark** ğŸ”¥ | **Hassan HOUSSEIN HOUMED** | Architecture donnÃ©es + KPIs analytiques |

---

## ğŸ¯ Mon RÃ´le : Data Engineering avec Hadoop & Spark

J'ai conÃ§u et implÃ©mentÃ© **l'infrastructure Big Data complÃ¨te** de ShopNow+ :

### ğŸ—ï¸ Architecture HDFS (3 couches)

```
/user/spark/kafka_stream/
â”œâ”€â”€ brut/                          # DonnÃ©es brutes Kafka
â”‚   â””â”€â”€ events/ â†’ [Parquet]
â”œâ”€â”€ curated/                       # DonnÃ©es filtrÃ©es par type d'Ã©vÃ©nement
â”‚   â”œâ”€â”€ view_product/
â”‚   â””â”€â”€ add_to_cart/
â””â”€â”€ indicators/                    # KPIs finaux (dashboards)
    â”œâ”€â”€ top_viewed_products/
    â”œâ”€â”€ top_bought_products/
    â”œâ”€â”€ daily_revenue/
    â”œâ”€â”€ stock_alerts/
    â””â”€â”€ global_stats/
```

**Logique** : 3 Ã©tapes de transformation (brut â†’ curated â†’ indicateurs) pour maintenir donnÃ©es propres et traÃ§abilitÃ©.

---

### âš™ï¸ Spark Jobs : Du Streaming au Batch

#### **Job 1 : Spark Streaming** (Ingestion)
- Consomme Ã©vÃ©nements Kafka (`VIEW_PRODUCT`, `ADD_TO_CART`)
- Sauvegarde en continu dans `/brut/events/` (format Parquet)
- Enrichissement et nettoyage

#### **Job 2 : Spark Batch** (Analytique)
- ExÃ©cution quotidienne (batch mode)
- Calcule 6 KPIs mÃ©tier Ã  partir des donnÃ©es brutes
- GÃ©nÃ¨re rÃ©sultats dans `/indicators/` pour visualisations

---

## ğŸ“Š KPIs MÃ©tier ImplÃ©mentÃ©s

J'ai mis en place **6 indicateurs clÃ©s** pour piloter ShopNow+ :

| KPI | Description | Valeur |
|-----|-------------|--------|
| **Top 10 Produits Vus** | Produits les plus consultÃ©s | Rang produits populaires |
| **Top 10 Produits AchetÃ©s + CA** | RentabilitÃ© rÃ©elle | Chiffre d'affaires par produit |
| **CA par Jour** | Tendance ventes | 346 620â‚¬ total / pic 124 650â‚¬ |
| **Alertes Rupture Stock** | Produits Ã  rÃ©approvisionner | 7 produits en alerte |
| **Produits par Gamme de Prix** | StratÃ©gie tarifaire | Distribution par prix |
| **Statistiques Globales** | SantÃ© plateforme | 2574 Ã©vÃ©nements, **39.6% taux conversion** |

**RÃ©sultats clÃ©s** :
- 1844 consultations â†’ 730 achats = **excellent taux de conversion (39.6%)**
- 7 produits en rupture de stock dÃ©tectÃ©s automatiquement
- Pipeline robuste : 0 perte de donnÃ©es, format Parquet compression 5-10Ã—

---

## ğŸ”„ Flux de DonnÃ©es Complet

```
Frontend (React)
    â†“ [Ã©vÃ©nements: VIEW_PRODUCT, ADD_TO_CART]
Backend (Express)
    â†“ [Kafka Producer]
Kafka Topic: ecommerce
    â†“ [Consumer]
Spark Streaming â†’ HDFS /brut/events/
    â†“ [Job quotidien]
Spark Batch â†’ HDFS /indicators/
    â†“ [Parquet optimisÃ©]
Dashboards & Visualisations
```

---

## ğŸ› ï¸ Stack Technique

### **Big Data**
- ![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) - Traitement distribuÃ©
- ![Hadoop HDFS](https://img.shields.io/badge/Hadoop%20HDFS-66CCFF?style=flat-square) - Stockage distribuÃ©
- ![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat-square&logo=apache-kafka&logoColor=white) - Streaming Ã©vÃ©nementiel
- ![Parquet](https://img.shields.io/badge/Parquet-FF6B6B?style=flat-square) - Format columaire

### **Backend (Ã‰quipe)**
- ![Node.js](https://img.shields.io/badge/Node.js-339933?style=flat-square&logo=node.js&logoColor=white) - Runtime
- ![Express.js](https://img.shields.io/badge/Express.js-000000?style=flat-square&logo=express&logoColor=white) - API REST
- ![MongoDB](https://img.shields.io/badge/MongoDB-13AA52?style=flat-square&logo=mongodb&logoColor=white) - Base donnÃ©es

### **Frontend (Ã‰quipe)**
- ![React](https://img.shields.io/badge/React-61DAFB?style=flat-square&logo=react&logoColor=black) - UI
- ![Vite](https://img.shields.io/badge/Vite-646CFF?style=flat-square&logo=vite&logoColor=white) - Build

### **DevOps**
- ![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white)
- ![Docker Compose](https://img.shields.io/badge/Docker%20Compose-2496ED?style=flat-square&logo=docker&logoColor=white)

---

## ğŸš€ Lancement du Projet

### **DÃ©marrer l'infrastructure Big Data + Backend**
```bash
docker compose up -d
```
â†’ Lance Hadoop, Spark, Kafka, MongoDB, Backend

### **Lancer le Frontend**
```bash
cd front
npm install
npm run dev
```
â†’ http://localhost:5173

### **Remplir la base de donnÃ©es**
```bash
cd back
npm start        # Serveur
npm run seed     # Ajouter donnÃ©es de test
```

---

## ğŸ’¡ DÃ©cisions Architecturales JustifiÃ©es

### **1. Batch vs Streaming (j'ai choisi Batch)**

| Approche | Pros | Cons | Mon choix |
|----------|------|------|----------|
| **Streaming** | KPIs temps rÃ©el | Complexe, ressources | Futur |
| **Batch** âœ… | Simple, fiable, suffisant | DÃ©lai 24h | Actuel |

**Justification** : Les alertes rupture stock sont gÃ©rÃ©es en temps rÃ©el via le backend. Les KPIs peuvent attendre le batch quotidien.

### **2. Format de Stockage : Parquet**

âœ… Compression 5-10Ã— (Ã©conomies de stockage)  
âœ… Format columaire (requÃªtes analytiques rapides)  
âœ… Standard Big Data (compatible Spark, Hive, etc.)

### **3. Partitionnement par Date**

```
/brut/events/2025-12-30/
/brut/events/2025-12-31/
```

Permet retrouver facilement toutes les commandes d'un jour â†’ **facilite incidents, rejeu, analyses**.

---

## ğŸ“ˆ RÃ©sultats & Impact

**DonnÃ©es traitÃ©es** : 2574 Ã©vÃ©nements  
**Conversion** : 39.6% (1844 vues â†’ 730 achats)  
**Chiffre d'affaires** : 346 620â‚¬  
**Alertes gÃ©nÃ©rÃ©es** : 7 produits en rupture de stock  
**FiabilitÃ© pipeline** : 100% (0 perte de donnÃ©es)

---

## ğŸ“ CompÃ©tences DÃ©montrÃ©es

- âœ… Architecture Big Data **scalable** (brut â†’ curated â†’ indicators)
- âœ… Spark Streaming + Spark Batch (dual job pattern)
- âœ… HDFS organisation et gestion de donnÃ©es
- âœ… Kafka intÃ©gration (producer/consumer)
- âœ… Optimisation formats (Parquet, compression)
- âœ… KPIs mÃ©tier (business analytics)
- âœ… Collabortation Ã©quipe (front/back/data)
- âœ… Docker & DevOps

---

## ğŸ‘¤ Auteur

**Hassan HOUSSEIN HOUMED**  
ğŸ“š MastÃ¨re 2 Big Data & Intelligence Artificielle - IPSSI Paris  
ğŸ“§ hassan.houssein.houmed@gmail.com  
ğŸ™ GitHub : https://github.com/HASSANHOUSSEINHOUMED

---

**DerniÃ¨re mise Ã  jour** : DÃ©cembre 2025
